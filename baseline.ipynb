{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline question answering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to read pdf and convert it into smaller chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import libraries\n",
    "import PyPDF2 \n",
    "\n",
    "# Function to read pdf\n",
    "def read_pdf(filepath:str) -> PyPDF2._reader.PdfReader:\n",
    "    reader = PyPDF2.PdfReader(filepath)\n",
    "    return reader\n",
    "\n",
    "# Function that returns only content of pdf as string\n",
    "def get_pdf_content(filepath:str) -> str:\n",
    "    reader = read_pdf(filepath=filepath)\n",
    "    pdf_content = ''\n",
    "    for page in reader.pages:\n",
    "        pdf_content += page.extract_text()\n",
    "    \n",
    "    return pdf_content\n",
    "\n",
    "\n",
    "# Function that takes large block of text and return list of smaller segments / chunks\n",
    "def content_to_segments(content:str, max_words:int = 250, overlap:int=20)->list[str]:\n",
    "    lines = content.split(' ')\n",
    "    chunks = []\n",
    "    \n",
    "    # Iterate through the lines with the specified overlap\n",
    "    for i in range(0, len(lines), max_words - overlap):\n",
    "        # Extract the chunk with the given number of lines, including overlap\n",
    "        chunk = \" \".join(lines[i:i + max_words])\n",
    "        chunks.append(chunk)\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = get_pdf_content(filepath='Data/computer.pdf')\n",
    "segments = content_to_segments(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question answering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sudarshan/anaconda3/envs/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepset/roberta-base-squad2\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"deepset/roberta-base-squad2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Main function that returns answer given a context\n",
    "def getAnswer(question:str, context:str)-> dict: \n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer.encode_plus(question, context, return_tensors=\"pt\")\n",
    "\n",
    "    # Get the input IDs and attention mask\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    # Get the start and end scores for the answer\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    start_scores = outputs.start_logits\n",
    "    end_scores = outputs.end_logits\n",
    "\n",
    "    # Apply softmax to get probabilities\n",
    "    start_probs = F.softmax(start_scores, dim=1).tolist()[0]\n",
    "    end_probs = F.softmax(end_scores, dim=1).tolist()[0]\n",
    "\n",
    "    # Get the most likely beginning and end of the answer span\n",
    "    start_index = torch.argmax(start_scores)\n",
    "    end_index = torch.argmax(end_scores)\n",
    "    \n",
    "    tokens = input_ids[0][start_index : end_index + 1]\n",
    "    answer = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "\n",
    "    # Certainty of answer\n",
    "    prob_score = (start_probs[start_index] + end_probs[end_index]) / 2\n",
    "\n",
    "    return {\n",
    "        'answer': answer,\n",
    "        'score' : prob_score\n",
    "    }\n",
    "\n",
    "\n",
    "## Get answer from multiple segments\n",
    "def getAnswerFromSegments(question:str, segments:list[str])->list[dict]:\n",
    "    answers = []\n",
    "    for segment in segments:\n",
    "        try:\n",
    "            ans = getAnswer(question=question, context=segment)\n",
    "            if(ans['answer'] != ''):\n",
    "                answers.append(ans)\n",
    "        except:\n",
    "            ...\n",
    "       \n",
    "    \n",
    "    try:\n",
    "        ans = max(answers, key=lambda x: x['score'])\n",
    "    except:\n",
    "        ans='No answer found'\n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40662/2490020308.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  test_data = pd.read_csv(\"Data/test_data.csv\", delimiter=\", \")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_data = pd.read_csv(\"Data/test_data.csv\", delimiter=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (802 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Questions answered\n",
      "2 Questions answered\n",
      "3 Questions answered\n",
      "4 Questions answered\n",
      "5 Questions answered\n",
      "6 Questions answered\n",
      "7 Questions answered\n",
      "8 Questions answered\n",
      "9 Questions answered\n",
      "10 Questions answered\n",
      "11 Questions answered\n",
      "12 Questions answered\n",
      "13 Questions answered\n",
      "14 Questions answered\n",
      "15 Questions answered\n",
      "16 Questions answered\n",
      "17 Questions answered\n",
      "18 Questions answered\n",
      "19 Questions answered\n",
      "20 Questions answered\n",
      "21 Questions answered\n",
      "22 Questions answered\n",
      "23 Questions answered\n",
      "24 Questions answered\n",
      "25 Questions answered\n"
     ]
    }
   ],
   "source": [
    "pred_answers = []\n",
    "n = len(test_data['question'])\n",
    "i = 1\n",
    "\n",
    "for question in test_data['question'][:n]:\n",
    "    ans = getAnswerFromSegments(question=question, segments=segments)\n",
    "    pred_answers.append(ans)\n",
    "    print(i, \"Questions answered\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No answer found'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_answers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ans = []\n",
    "for pred in pred_answers:\n",
    "    try:\n",
    "        ans.append(pred['answer'].replace(\"\\n\", \" \"))\n",
    "    except:\n",
    "        ans.append(pred)\n",
    "    \n",
    "model_result = pd.DataFrame({'question' : test_data['question'][:n], \n",
    "                            'answer' : test_data['answer'][:n], \n",
    "                            'pred_answers': ans})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result.to_csv('Data/test_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47493"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "s    22\n",
       "l     3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Baseline model Evolution\n",
    "### Used PDF\n",
    "**Pdf used** : Computer Science Grade 10 [English version]  \n",
    "\n",
    "**PDF size** : 257 pages, 4354 Lines, 47493 Words\n",
    "\n",
    "### Models used\n",
    "\n",
    "**Model** : deepset/roberta-base-squad2\n",
    "\n",
    "**Tokenizer** : deepset/roberta-base-squad2 \n",
    "\n",
    "### Segmentation\n",
    "**Max words** : 250\n",
    "\n",
    "**Overlap** : 20\n",
    "\n",
    "**No of chunks** : 207\n",
    "\n",
    "### Testing dataset\n",
    "**No of questions** : 25\n",
    "\n",
    "**Types** : 22 short and 3 long\n",
    "\n",
    "### Result\n",
    "**Time taken** : 55 min 45.2 sec\n",
    "\n",
    "**Average time** : 2 min 13.8 sec\n",
    "\n",
    "**Fully Correct**: 8 (6 Terminology,  2 Sentence)\n",
    "\n",
    "**somehow right**: 2 (2 Sentence)\n",
    "\n",
    "**partial answer**: 5 (3 Point based LQ, 1 Sentence, 1 Terminology)\n",
    "\n",
    "**No ans**: 5\n",
    "\n",
    "**Wrong** : 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
